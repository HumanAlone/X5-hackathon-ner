{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcad63f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sergey\\Documents\\VS Code Projects\\LCT-2025\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    EarlyStoppingCallback,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e7e7859",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"train.csv\"\n",
    "data = pd.read_csv(path, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d290391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем метки\n",
    "label_list = [\n",
    "    \"O\",\n",
    "    \"B-TYPE\",\n",
    "    \"I-TYPE\",\n",
    "    \"B-BRAND\",\n",
    "    \"I-BRAND\",\n",
    "    \"B-VOLUME\",\n",
    "    \"I-VOLUME\",\n",
    "    \"B-PERCENT\",\n",
    "    \"I-PERCENT\",\n",
    "]\n",
    "\n",
    "\n",
    "# Создаем mapping\n",
    "label_to_id = {label: i for i, label in enumerate(label_list)}\n",
    "id_to_label = {i: label for i, label in enumerate(label_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a74ccb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Выбор устройства\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c885579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Загрузка модели и токенизатора\n",
    "model_name = \"distilbert-base-multilingual-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name, num_labels=len(label_list), id2label=id_to_label, label2id=label_to_id\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf0d648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_annotation_row_simple(row):\n",
    "    text = row[\"sample\"]\n",
    "    annotation_str = row[\"annotation\"]\n",
    "\n",
    "    fixed_annotation = (\n",
    "        annotation_str.replace(\"'0'\", \"'O'\")\n",
    "        .replace(\"'0,\", \"'O',\")\n",
    "        .replace(\",0'\", \",O'\")\n",
    "    )\n",
    "\n",
    "    return {\"text\": text, \"annotations_str\": fixed_annotation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07864df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(example):\n",
    "    try:\n",
    "        annotations = eval(example[\"annotations_str\"])\n",
    "    except:\n",
    "        print(f\"Ошибка парсинга: {example['annotations_str']}\")\n",
    "        annotations = []\n",
    "\n",
    "    # Токенизация\n",
    "    tokenized = tokenizer(\n",
    "        example[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        return_offsets_mapping=True,\n",
    "        is_split_into_words=False,\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, offset in enumerate(tokenized[\"offset_mapping\"]):\n",
    "        start, end = offset\n",
    "        if start == end == 0:\n",
    "            labels.append(-100)\n",
    "            continue\n",
    "\n",
    "        label_found = False\n",
    "        for ann_start, ann_end, label in annotations:\n",
    "            if start >= ann_start and end <= ann_end:\n",
    "                if start == ann_start:\n",
    "                    labels.append(label_to_id[label])\n",
    "                else:\n",
    "                    labels.append(label_to_id[label.replace(\"B-\", \"I-\")])\n",
    "                label_found = True\n",
    "                break\n",
    "\n",
    "        if not label_found:\n",
    "            labels.append(label_to_id[\"O\"])\n",
    "\n",
    "    tokenized[\"labels\"] = labels\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06115f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 27251/27251 [00:08<00:00, 3328.35 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создан датасет с 27251 примерами\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "parsed_data = [parse_annotation_row_simple(row) for _, row in data.iterrows()]\n",
    "dataset = Dataset.from_list(parsed_data)  # ← ВОТ ОН!\n",
    "tokenized_dataset = dataset.map(tokenize_and_align_labels)\n",
    "print(f\"Создан датасет с {len(dataset)} примерами\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "160adae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe8eb3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделяем данные\n",
    "train_test = tokenized_dataset.train_test_split(test_size=0.2, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a4040c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    warmup_steps=500,\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.15,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=500,\n",
    "    eval_steps=500,\n",
    "    save_steps=1000,\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    disable_tqdm=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2146a645",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_test[\"train\"],\n",
    "    eval_dataset=train_test[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[\n",
    "        EarlyStoppingCallback(early_stopping_patience=4, early_stopping_threshold=0.01)\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7603a7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4500' max='6815' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4500/6815 10:52 < 05:35, 6.89 it/s, Epoch 3/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.327925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.337442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.072800</td>\n",
       "      <td>0.341201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.051400</td>\n",
       "      <td>0.335988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>0.297786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.050800</td>\n",
       "      <td>0.354510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.038700</td>\n",
       "      <td>0.322251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.042700</td>\n",
       "      <td>0.360993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.029700</td>\n",
       "      <td>0.370858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4500, training_loss=0.0521611631181505, metrics={'train_runtime': 652.4981, 'train_samples_per_second': 167.05, 'train_steps_per_second': 10.444, 'total_flos': 188100983610288.0, 'train_loss': 0.0521611631181505, 'epoch': 3.301540719002201})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7dcf8627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель сохранена в папку ./ner_model_v4\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"./ner_model_v4\")\n",
    "tokenizer.save_pretrained(\"./ner_model_v4\")\n",
    "print(\"Модель сохранена в папку ./ner_model_v4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6421f30",
   "metadata": {},
   "source": [
    "### Первый вариант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4b7e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data = pd.read_csv(\"submission.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb8cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_to_annotations(text, predictions, offset_mapping):\n",
    "    annotations = []\n",
    "\n",
    "    i = 0\n",
    "    while i < len(offset_mapping):\n",
    "        start, end = offset_mapping[i]\n",
    "        if start == end == 0:\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        word_label = id_to_label[predictions[i]]\n",
    "\n",
    "        j = i + 1\n",
    "        while j < len(offset_mapping):\n",
    "            next_start, next_end = offset_mapping[j]\n",
    "            if next_start == end:\n",
    "                end = next_end\n",
    "                j += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        annotations.append((start.item(), end.item(), word_label))\n",
    "        i = j\n",
    "\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3848824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_annotations(text):\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        return_offsets_mapping=True,\n",
    "    )\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)[0].cpu().numpy()\n",
    "\n",
    "    return predictions_to_annotations(text, predictions, offset_mapping[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ae3eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказания для всех примеров\n",
    "submission_annotations = []\n",
    "for text in submission_data[\"sample\"]:\n",
    "    ann = predict_annotations(text)\n",
    "    submission_annotations.append(str(ann))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a859c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(\n",
    "    {\"sample\": submission_data[\"sample\"], \"annotation\": submission_annotations}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ac7bcaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предсказания сохранены в submission_2.csv\n"
     ]
    }
   ],
   "source": [
    "# Сохраняем в файл\n",
    "result_df.to_csv(\"test_submission/submission_2.csv\", sep=\";\", index=False)\n",
    "print(\"Предсказания сохранены в submission_2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
